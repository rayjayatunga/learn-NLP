{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Basic Definitions\n",
        "\n",
        "* Sentence: sequence of words that begins with a capitalized word and ends with a period.\n",
        "\n",
        "* Tokens: Can be words, sub-units of words and punctuation marks\n",
        "\n",
        "* Characters: represents atomic symbols that compose a string\n",
        "\n",
        "* Corpus: large collection of writings used for linguistic analysis\n",
        "\n",
        "* N-Gram: simply refers to N consecutive items or tokens whether words, subwords or tokens. Single tokens may be called unigrams.\n",
        "\n"
      ],
      "metadata": {
        "id": "XIduXDT9Ub4p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bag of words:\n",
        "\n",
        "Text is sequential and the order of words in a sentence matter for the meaning of the sentence. Some NLP approaches do not consider the relationships between words in a sentence. These algorithms are called 'bag of words' representations\n",
        "\n",
        "Consider the phrases dog toy vs toy dog - 2 very different concepts. The bag of word approach will not be good at making a distinction there.\n",
        "\n"
      ],
      "metadata": {
        "id": "L61GaI2e2s42"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normalization of Vectors\n",
        "\n",
        "Assume we create vectors based on counting the occurrences of specific words (count vectors) in a vocabulary. Some documents will be long while others will be shorter. As a results our count vectors will have size disparities (more words = higher counts). To address this we need to **normalize** our vectors.\n",
        "\n",
        "One way to normalize a vector is to divide by the square root of the sum of squares of each element (L2 norm)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UZ2gxMJs3epJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization"
      ],
      "metadata": {
        "id": "7JRGa9kj3ePI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s1 = \"I like cats\"\n",
        "#To split the string I can call the string method split()\n",
        "#By default the string function splits on whitespace.\n",
        "s1.split()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwFw1uEdDr-z",
        "outputId": "09e29240-9fdf-4949-dc0c-0266f6116f14"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I', 'like', 'cats']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Punctuation could be important for downstream NLP tasks. For example \"I hate cats.\" vs \"I hate cats?\" could mean 2 separate things. Thus choosing the right tokenization strategy is important"
      ],
      "metadata": {
        "id": "cng9lCcG3eRw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s2 = \"I hate cats.\"\n",
        "s3 = \"I hate cats?\"\n",
        "\n",
        "#print out the tokens side by side for each token of s2 and s3 using the string.split() method\n",
        "for i in range(len(s2.split())):\n",
        "  print(\"s2: \" + s2.split()[i] + \"|  s3: \" + s3.split()[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sY-EjW6LEvOI",
        "outputId": "4c99e644-ce18-4041-e199-a51335ac1eec"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "s2: I|  s3: I\n",
            "s2: hate|  s3: hate\n",
            "s2: cats.|  s3: cats?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By keeping punctuation with the words, we need more data as cats. and cats? are seen as 2 separate tokens."
      ],
      "metadata": {
        "id": "8T1ZoiUq3eXe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Character based tokenization:\n",
        "\n",
        "In English there are a limited number of characters. The advantage is that our vocab size will be small.\n",
        "\n",
        "The disadvantage is that Characters don't contain lots of information unlike word based tokenization.\n",
        "\n",
        "### Sub-word tokenization\n",
        "\n",
        "A middle ground between word based and character based tokenization is sub-word tokenization. Consider the example *walking* which can be decomposed into *walk* + *ing*. \"Walk\" is closely related to \"walking\"  so we want the model to have some shared representation in our ML model. ing should be seen as a modifier on the word walking. If we don't split walking, our model may see the walk as being no closer to walking than it is to \"eat\" or \"capture\".\n",
        "\n",
        "Although sub-word tokenization is a good middle ground between word based and character based tokenization, it's not necessary for a good model."
      ],
      "metadata": {
        "id": "gq2J_O8uGoos"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stop words\n",
        "\n",
        "Common words such as \"and\", \"it\", \"the\", \"a\", \"is\" etc are don't necessarily carry a lot of information on their own.\n",
        "\n",
        "One reason to remove stop words is because they can **increase dimensionality**. Increasing dimensionality is bad - we prefer not to have high dimensional vectors because this requires more computation and memory.\n",
        "\n",
        "Another reason is that if we use a count vectorization strategy, documents will be clustered close together based on having a similar number of the stop words. This reduces the ability to distinguish between different concepts.\n",
        "\n"
      ],
      "metadata": {
        "id": "sjQe1FHtGqpC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stemming and Lemmatization\n",
        "\n",
        "####Stemming\n",
        "Stemming chops off the ends of the word i.e running -> run\n"
      ],
      "metadata": {
        "id": "9eiWF8CHLjHF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Most common stemming algorithm is porter stemmer\n",
        "from nltk.stem import PorterStemmer\n",
        "porter = PorterStemmer()\n",
        "porter.stem(\"walking\") #returns walk\n",
        "porter.stem(\"procrastinating\") #returns procrastin which is not a real word"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Lb-Wg7G7jlBK",
        "outputId": "747322ee-1fc8-4e81-b47d-6b09566d295a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'procrastin'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "VPKDD0HFrMjg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "Q7gFhmM0qokc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "porter = PorterStemmer()"
      ],
      "metadata": {
        "id": "f9LuWwzwquKl"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "porter.stem(\"walking\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3MBkgUWAqzsS",
        "outputId": "ed1a9db5-296c-4b7e-c544-21ab95fdca38"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'walk'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "porter.stem(\"walked\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "NkHRkCkIq44W",
        "outputId": "ef367eae-53fd-4e2b-aabb-88e1e74dd8c8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'walk'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "porter.stem(\"ran\") #Did not return the root word run"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4k4j3_z_q7yD",
        "outputId": "0034a5be-8b53-43ca-b792-d33de50a8c0c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ran'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "porter.stem(\"replacement\") #returns replac - not a real word"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "OaCyRZO4rDYV",
        "outputId": "98f08eba-5ed3-41fd-e469-bc768d11bb75"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'replac'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"Lemmatization is more sophisticated than stemming\"\n",
        "words = sentence.split() #returns a list of individual words in the sentence\n",
        "for word in words:\n",
        "  print(porter.stem(word), end=\" \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoFcHDHYra3b",
        "outputId": "82777dfb-0072-47e6-af42-9ba323b43869"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lemmat is more sophist than stem "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Lemmatization"
      ],
      "metadata": {
        "id": "R4Kw0BdxsFYL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lemmatization will give you the true root word i.e swam -> swim, procrastinating -> procrastinate, better -> good, was -> be"
      ],
      "metadata": {
        "id": "VbKZuY1-LkoL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "import nltk"
      ],
      "metadata": {
        "id": "H9dPg11OLfxb"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#download the wordnet dictionary\n",
        "nltk.download(\"wordnet\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfvrYxy1kr-N",
        "outputId": "b6469d8c-2ba5-4a02-9172-7f4925d25eea"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "wordlist = [\"mice\", \"going\", \"better\"]\n",
        "for word in wordlist:\n",
        "  root = lemmatizer.lemmatize(word)\n",
        "  print(root)\n",
        "  #One problem with using lemmatizer.lemmatize is that it uses the noun POS by default\n",
        "  # going is a verb and better is an adjective so\n",
        "  # those need to be handled by passing the pos argument 'v' and 'a' respectively"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VgwIIbqk4-m",
        "outputId": "5ece7b78-854f-4f4f-e330-750b5e608e4e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mouse\n",
            "going\n",
            "better\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize(\"walking\") #walking is a verb not a noun, so by default we will get the same word"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "AhRc6i3vs2j6",
        "outputId": "59b18b57-1122-4069-fca8-711045714807"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'walking'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize(\"walking\" , pos= \"v\") #by passing the part of speech tag 'v' we are saying we want the root word of the verb \"walking\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0SE836WotIAH",
        "outputId": "eae4586c-c801-4bb0-8251-c22cf868c6c8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'walk'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize(\"better\" , pos= 'a')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "m2ZVsipFtH3f",
        "outputId": "a22553dc-a5d9-42f9-852c-781fed02d967"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'good'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### POS - Part of Speech and Lemmatization\n",
        "\n",
        "The root form of a verb is dependent on its POS. For example:\n",
        "\n",
        "> \"Donald Trump has a devoted following\"\n",
        "\n",
        "In this example, \"following\" is a noun, whereas in the below example:\n",
        "\n",
        "> \"The cat was following the bird as it flew by\"\n",
        "\n",
        "\"Following\" is a verb in this context\n",
        "\n",
        "In the first case, the root form of the word is \"following\" while in the second the root form of the word is \"follow\".\n"
      ],
      "metadata": {
        "id": "fbF8xdBbmlNo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Applications of Stemming and Lemmatization\n",
        "\n",
        "- Search Engines and Document retrieval\n",
        "- online ads\n",
        "- social media tags\n",
        "\n",
        "#### Search Engines\n",
        "\n",
        "- When a user enters a query, we don't want to return only results that are exact matches of that because we would miss equally relevant results that have variations in the form of the query. Thus we can get more matches by converting the word to its root form\n",
        "\n",
        "#### Online Advertizing\n",
        "\n",
        "- Ads are based on keywords. Advertizers need to match your ads to the search terms. Advertizers must pay ad platforms each time their ad is shown to a user. Therefore it is important to only show the ad when the search term is relevant to the topic of the ad"
      ],
      "metadata": {
        "id": "QHLbNeEPnszn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### POS Tagging\n",
        "\n",
        "NLTK has a POS tagger. However, the POS tags returned by the NLTK parts of speech tagger aren't compatible with the format the lemmatizer expects"
      ],
      "metadata": {
        "id": "ajhQJC7quMyh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_wordnet_pos(treebank_tag:str):\n",
        "  if treebank_tag.startswith('J'):\n",
        "    return wordnet.ADJ\n",
        "  elif treebank_tag.startswith('V'):\n",
        "    return wordnet.VERB\n",
        "  elif treebank_tag.startswith('N'):\n",
        "    return wordnet.NOUN\n",
        "  elif treebank_tag.startswith('R'):\n",
        "    return wordnet.ADV\n",
        "  else:\n",
        "    return wordnet.NOUN\n"
      ],
      "metadata": {
        "id": "moNUam_OrJEo"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MPndN78uSie",
        "outputId": "352c5d06-fd84-4bf3-a0f9-c0fa4c134fc3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = \"Donald Trump has a devoted following\".split()\n"
      ],
      "metadata": {
        "id": "sYRJQ6D7JbGS"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#run a POS tagger\n",
        "\n",
        "words_and_tags = nltk.pos_tag(words) #returns a list of tuples containing the word and corresponding tag\n",
        "words_and_tags"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqyPMHJOJkdL",
        "outputId": "12ca35fc-2e70-44b8-ceb3-a2d91f1e7ab7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Donald', 'NNP'),\n",
              " ('Trump', 'NNP'),\n",
              " ('has', 'VBZ'),\n",
              " ('a', 'DT'),\n",
              " ('devoted', 'VBN'),\n",
              " ('following', 'NN')]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word,tag in words_and_tags:\n",
        "  lemma = lemmatizer.lemmatize(word, pos = get_wordnet_pos(tag))\n",
        "  print(lemma, end = \" \")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6udra4czKI_N",
        "outputId": "90c3a934-4475-4dbc-dc4b-6d6ad6a2810a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Donald Trump have a devote following "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words_2 = \"The cat was following the bird as it flew by\".split()"
      ],
      "metadata": {
        "id": "qgL1b7h8LD2Q"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words_and_tags = nltk.pos_tag(words_2)\n",
        "words_and_tags1`"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C90VvsQLLL-8",
        "outputId": "dd8153fc-5833-4023-ca4e-698fd3cb886d"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('The', 'DT'),\n",
              " ('cat', 'NN'),\n",
              " ('was', 'VBD'),\n",
              " ('following', 'VBG'),\n",
              " ('the', 'DT'),\n",
              " ('bird', 'NN'),\n",
              " ('as', 'IN'),\n",
              " ('it', 'PRP'),\n",
              " ('flew', 'VBD'),\n",
              " ('by', 'IN')]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word, tags in words_and_tags:\n",
        "  lemma = lemmatizer.lemmatize(word, pos = get_wordnet_pos(tags))\n",
        "  print(lemma, end = \" \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krzWETYuL3Z9",
        "outputId": "9f8724ed-9ea0-44b4-87b3-da2a538bcf10"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The cat be follow the bird a it fly by "
          ]
        }
      ]
    }
  ]
}